{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3, Lesson 5, Activity 11: End-to-end IE application\n",
    "\n",
    "&copy;2021, Ekaterina Kochmar \\\n",
    "(revised: Nadejda Roubtsova, June 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this activity is to:\n",
    "\n",
    "- To implement all the steps discussed in the lecture and apply your IE algorithm to the set of sentences and questions provided with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Understand the task\n",
    "\n",
    "In this task you will aim to extract actions and corresponding participants from raw text in order to get answers to queries such as \"Who did Joe Biden meet with?\" \\\n",
    "Let us start with the following simpler case of preprocessed data. Can you programmatically extract participant 2 (`p2`) from the data tuples in `meetings` given that participant 1 (`p1`) is Joe Biden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetings = [('Boris Johnson', 'meets with', 'the Queen'),\n",
    "            ('Joe Biden', 'meets with', 'his cabinet'),\n",
    "            ('administration', 'meets with', 'tech giants'),\n",
    "            ('the Queen', 'meets with', 'the Prime Minister'),\n",
    "            ('Joe Biden', 'meets with', 'Russian President')]\n",
    "# query: Who does Joe Biden meet with?\n",
    "answer = [# enter code here: p2 for tuples in meetings if p1=='Joe Biden'\n",
    "         ]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"meeting\" is a mutual action, a participant may appear on the right or on the left. Let's make sure both cases are covered. Try another query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query: Who did the Queen meet with?\n",
    "answer   = [# enter code here: p2 for tuples in meetings if p1=='the Queen'\n",
    "           ]\n",
    "answer +=  [# enter code here: p1 for tuples in meetings if p2=='the Queen'\n",
    "           ]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get more practice with NLP using spaCy\n",
    "\n",
    "Apply `spaCy`'s `nlp` pipeline to some input text. Do you agree with the output: e.g., are all PoS assinged to these words correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Beware the Jabberwock, my son! The jaws that bite, the claws that catch! \" +\n",
    "          \"Beware the Jubjub bird, and shun The frumious Bandersnatch!\")\n",
    "\n",
    "rows = []\n",
    "rows.append([\"Word\", \"Position\", \"Lowercase\", \"Lemma\", \"POS\", \"Alphanumeric\", \"Stopword\"])\n",
    "for token in doc:\n",
    "    rows.append([token.text, str(token.i), token.lower_, token.lemma_, \n",
    "                 token.pos_, str(token.is_alpha), str(token.is_stop)])\n",
    "\n",
    "columns = zip(*rows)\n",
    "column_widths = [max(len(item) for item in col) for col in columns]\n",
    "for row in rows:\n",
    "    print(''.join(' {:{width}} '.format(row[i], width=column_widths[i]) \n",
    "                  for i in range(0, len(row))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify all noun phrases in a sentence. Is this output correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"On Friday, board members meet with senior managers \" +\n",
    "          \"to discuss future development of the company.\")\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    # here you return the noun phrase, its head (main) noun, the dependency relation linking\n",
    "    # this noun to its own head in the parse tree, and the head of the noun in the parse tree\n",
    "    print('\\t'.join([chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at all the dependencies for all words in a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(# the token itself, the dependency relation for the token,\n",
    "          # the head to which the token is linked, the head's PoS,\n",
    "          # the list of all dependents of the token (token.children)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract information\n",
    "\n",
    "Here is how you can identify the participants of a particular action (e.g., when the action is expressed with \"meet\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.lemma_==\"meet\" and token.pos_==\"VERB\" and token.dep_==\"ROOT\":\n",
    "        action = token.text\n",
    "        children = [child for child in token.children]\n",
    "        participant1 = \"\"\n",
    "        participant2 = \"\"\n",
    "        for child1 in children:\n",
    "            if child1.dep_==\"nsubj\":\n",
    "                participant1 = \" \".join([attr.text for \n",
    "                                         attr in child1.children]) + \" \" + child1.text\n",
    "            elif child1.text==\"with\":\n",
    "                action += \" \" + child1.text\n",
    "                child1_children = [child for child in child1.children]\n",
    "                for child2 in child1_children:\n",
    "                    if child2.pos_ == \"NOUN\":\n",
    "                        participant2 = \" \".join([attr.text for \n",
    "                                             attr in child2.children]) + \" \" + child2.text\n",
    "print (f\"Participant1 = {participant1}\")\n",
    "print (f\"Action = {action}\")\n",
    "print (f\"Participant2 = {participant2}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's improve this code so that it can deal with different formats of the expression, and apply it to various sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"On Friday, board members meet with senior managers \" +\n",
    "             \"to discuss future development of the company.\", \n",
    "             \"Boris Johnson met with the Queen last week.\",\n",
    "             \"Joe Biden meets the Queen at Buckingham Palace.\",\n",
    "             \"The two leaders also posed for photographs and \" +\n",
    "             \"the President talked to reporters.\"]\n",
    "\n",
    "def extract_information(doc):\n",
    "    action=\"\"\n",
    "    participant1 = \"\"\n",
    "    participant2 = \"\"\n",
    "    for token in doc:\n",
    "        if # check that the token's lemma is \"meet\", its PoS is VERB and \n",
    "           # it's the ROOT of the whole sentence (i.e., the main verb)\n",
    "            action = token.text\n",
    "            children = [child for child in token.children]   \n",
    "            for child1 in children:\n",
    "                if # check that child1 is a subject (i.e., it's related to the verb with the 'nsubj' relation)\n",
    "                    participant1 = \" \".join([attr.text for \n",
    "                                             attr in child1.children]) + \" \" + child1.text\n",
    "                elif child1.text==\"with\": # i.e., if the verb attaches \"with\" (as in \"meet with\")\n",
    "                    action += \" \" + child1.text\n",
    "                    child1_children = [child for child in child1.children]\n",
    "                    for child2 in child1_children:\n",
    "                        if # check that child2 is either a common noun (NOUN, e.g., \"members\") \n",
    "                        # or a proper noun (PROPN, e.g., \"Joe\")\n",
    "                            participant2 = \" \".join([attr.text for \n",
    "                                                 attr in child2.children]) + \" \" + child2.text\n",
    "                elif # check if child1 is a direct object (the dependency relation is 'dobj')\n",
    "                # and it is either a common or a proper noun\n",
    "                    participant2 = \" \".join([attr.text for \n",
    "                                             attr in child1.children]) + \" \" + child1.text\n",
    "    print (f\"Participant1 = {participant1}\")\n",
    "    print (f\"Action = {action}\")\n",
    "    print (f\"Participant2 = {participant2}\")\n",
    "\n",
    "for sent in sentences:\n",
    "    print(f\"\\nSentence = {sent}\")\n",
    "    doc = nlp(sent)\n",
    "    extract_information(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
